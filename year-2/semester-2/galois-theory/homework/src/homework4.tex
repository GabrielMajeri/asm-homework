\section*{Homework 4}

\setcounter{exercise}{0}

\begin{exercise}
Let \(k \subseteq E\) be a finite extension of fields and \(V\) a finite-dimensional \(k\)-vector space. Show that:
\begin{enumerate}[(i)]
    \item \(\Hom_k \left(E \tensor_k E, E \tensor_k V^*\right) \cong \Hom_k \left(E \tensor_k V, \End_k(E)\right)\)

    \item Under the 1-to-1 correspondence stated above, to a bijective morphism there corresponds a bijective one.
\end{enumerate}
\end{exercise}
\begin{solution}
Let \(V\) and \(W\) be two finite-dimensional \(k\)-vector spaces. Fix a basis \(e_i\) of \(V\) and let \(e^i\) be the corresponding dual basis. Then we have an isomorphism between \(\Hom_k (V, W)\) and \(V^* \tensor_k W\) given by:
\begin{align*}
    \Hom_k (V, W) &\to V^* \tensor_k W & V^* \tensor_k W &\to \Hom_k (V, W) \\
    f &\mapsto \sum_{i} e^{i} \tensor_k f(e_i) & \alpha \tensor w &\mapsto \left(v \mapsto \alpha(v) \cdot w\right)
\end{align*}
In particular, since \(\End_k (E) = \Hom_k (E, E)\) is finite-dimensional over \(k\), we get \(\End_k (E) \cong E^* \tensor E\).

\begin{enumerate}[(i)]
    \item Using the isomorphism mentioned above, we obtain
    \begin{align*}
        \Hom_k \left(E \tensor_k E, E \tensor_k V^*\right) &\cong \left(E \tensor_k E\right)^* \tensor_k \left(E \tensor_k V^*\right) \\
        &\cong E^* \tensor_k E^* \tensor_k E \tensor_k V^* \\
        &\cong E^* \tensor_k V^* \tensor_k E^* \tensor_k E \\
        &\cong \left(E^* \tensor_k V^*\right) \tensor_k \left(E^* \tensor_k E\right) \\
        &\cong \left(E \tensor_k V\right)^* \tensor_k \Hom_k (E, E) \\
        &\cong \Hom_k \left(E \tensor_k V, \End_k (E)\right)
    \end{align*}

    \item In the isomorphism \(\Hom_k (V, W) \cong V^* \tensor_k W\), a linear map \(f \in \Hom_k (V, W)\) of rank \(r\) (i.e. \(\dim_k (\ima f) = r\)) gets mapped to a tensor \(T \in V^* \tensor_k W\) of rank \(r\) (i.e. it is a sum of no fewer than \(r\) simple tensors). The same holds when taking a tensor \(T \in E^* \tensor_k E\) to a map \(f \in \Hom_k (E, E) = \End_k (E)\).

    The other operations we perform on the intermediary tensor products do \emph{not} affect the ranks of the tensors involved. In particular, the rank doesn't change when going from \((V \tensor_k W)^*\) to \(V^* \tensor_k W^*\), nor when going from \(V \tensor_k W\) to \(W \tensor_k V\).

    If \(f \in \Hom_k \left(E \tensor_k E, E \tensor_k V^*\right)\) is bijective, then it has full rank. It will correspond to a linear map of full rank in \(\Hom_k \left(E \tensor_k V, \End_k(E)\right)\). By the rank-nullity theorem, this map is also bijective.
\end{enumerate}
\end{solution}

\begin{exercise}
Let \(H_n\) be the unital \(k\)-algebra generated by \(g\) and \(x\) with relations \(g^n = 1\), \(x^n = 0\) and \(xg = \omega gx\) (\(n \in \naturals\), \(n > 1\) and \(\omega \in \complex\) is a primitive \(n\)-th root of unity). Prove that \(H_n\) is a Hopf algebra of dimension \(n^2\) with the structure given by
\begin{align*}
    \Delta(g) &= g \tensor g  & \varepsilon(g) &= 1 & S(g) &= g^{-1} \left(= g^{n-1}\right) \\[1em]
    \Delta(x) &= x \tensor 1 + g \tensor x & \varepsilon(x) &= 0 & S(x) &= - g^{-1} x
\end{align*}
(\(\Delta\) and \(\varepsilon\) extend as algebra homomorphisms, \(S\) extends as an anti-algebra homomorphism)
\end{exercise}
\begin{proof}
As a vector space, \(H_n\) has a basis consisting of the elements \(1, g, g^2, \dots, g^{n-1}\), the elements \(x, x^2, \dots, x^{n-1}\) and all elements of the form \(g^{k} x^{l}\) with \(k, l = \overline{1, n - 1}\). This gives us a total of 
\[
    n + (n - 1) + (n - 1)(n - 1) = n + (n - 1) + (n^2 - 2n + 1) = n^2
\]
basis elements, hence \(\dim H_n = n^2\).

Since \(H_n\) is already a unital \(k\)-algebra, we just need to check the remaining conditions for it to be a Hopf algebra. It suffices to verify them on the algebra generators, \(g\) and \(x\).
\begin{itemize}
    \item \(\Delta\) is \textbf{coassociative} \(\iff\) \((\Delta \tensor \Id) \Delta \equiv (\Id \tensor \Delta) \Delta\). We can check that this condition holds on the generators.

    For \(g\):
    \begin{gather*}
        \Delta(g) = g \tensor g \\
        (\Delta \tensor \Id) (g \tensor g) = (g \tensor g) \tensor g \\
        (\Id \tensor \Delta) (g \tensor g) = g \tensor (g \tensor g)
    \end{gather*}

    For \(x\):
    \begin{gather*}
        \Delta(x) = x \tensor 1 + g \tensor x \\
        \begin{aligned}
            (\Delta \tensor \Id) (x \tensor 1 + g \tensor x) &= (\Delta \tensor \Id) (x \tensor 1) + (\Delta \tensor \Id) (g \tensor x) \\
            &= (x \tensor 1 + g \tensor x) \tensor 1 + (g \tensor g) \tensor x \\
            &= x \tensor 1 \tensor 1 + g \tensor x \tensor 1 + g \tensor g \tensor x
        \end{aligned} \\
        \begin{aligned}
            (\Id \tensor \Delta) (x \tensor 1 + g \tensor x) &= (\Id \tensor \Delta) (x \tensor 1) + (\Id \tensor \Delta) (g \tensor x) \\
            &= x \tensor (1 \tensor 1) + g \tensor (x \tensor 1 + g \tensor x) \\
            &= x \tensor 1 \tensor 1 + g \tensor x \tensor 1 + g \tensor g \tensor x
        \end{aligned}
    \end{gather*}

    \item \(\varepsilon\) is \textbf{counit} for \(\Delta\) \(\iff\) \((\varepsilon \tensor \Id) \Delta \equiv \Id \equiv (\Id \tensor \varepsilon) \Delta\). This condition can also be checked on the algebra generators.

    For \(g\):
    \begin{gather*}
        (\varepsilon \tensor \Id) (g \tensor g) = 1 \tensor g \\
        (\Id \tensor \varepsilon ) (g \tensor g) = g \tensor 1
    \end{gather*}

    For \(x\):
    \begin{align*}
        (\varepsilon \tensor \Id) (x \tensor 1 + g \tensor x) &= (\varepsilon \tensor \Id) (x \tensor 1) + (\varepsilon \tensor \Id) (g \tensor x) \\
        &= 0 \tensor 1 + 1 \tensor x \\
        &= 1 \tensor x
    \end{align*}
    \begin{align*}
        (\Id \tensor \varepsilon) (x \tensor 1 + g \tensor x) &= (\Id \tensor \varepsilon) (x \tensor 1) + (\Id \tensor \varepsilon) (g \tensor x) \\
        &= x \tensor 1 + g \tensor 0 \\
        &= x \tensor 1
    \end{align*}

    \item \(S\) is an \textbf{antipode} \(\iff\) \(m_H (S \tensor \Id) \Delta \equiv \eta \varepsilon \equiv m_H (\Id \tensor S) \Delta\), where \(m_H\) is the multiplication map and \(\eta\) is the unit. We will again check this on the generators:

    For \(g\):
    \[
        \eta (\varepsilon (g)) = \eta (1) = 1
    \]
    \begin{align*}
        (m_H (S \tensor \Id) \Delta) (g) &= m_H (S \tensor \Id) (g \tensor g) \\
        &= m_H \left(g^{n - 1} \tensor g\right) \\
        &= g^{n - 1} \cdot g = g^n = 1
    \end{align*}
    \begin{align*}
        (m_H (\Id \tensor S) \Delta) (g) &= m_H (\Id \tensor S) (g \tensor g) \\
        &= m_H \left(g \tensor g^{n - 1}\right) \\
        &= g \cdot g^{n - 1} = g^n = 1
    \end{align*}

    For \(x\):
    \[
        \eta(\varepsilon(x)) = \eta (0) = 0
    \]
    \begin{align*}
        (m_H (S \tensor \Id) \Delta) (x) &= m_H (S \tensor \Id) (x \tensor 1 + g \tensor x) \\
        &= m_H (S \tensor \Id) (x \tensor 1) + m_H (S \tensor \Id) (g \tensor x) \\
        &= m_H (- g^{-1} x \tensor 1) + m_H (g^{-1} \tensor x) \\
        &= -g^{-1} x + g^{-1} x = 0
    \end{align*}
    \begin{align*}
        (m_H (\Id \tensor S) \Delta) (x) &= m_H (\Id \tensor S) (x \tensor 1 + g \tensor x) \\
        &= m_H (\Id \tensor S) (x \tensor 1) + m_H (\Id \tensor S) (g \tensor x) \\
        &= m_H (x \tensor 1) + m_H (g \tensor -g^{-1} x) \\
        &= x - g \cdot g^{-1} x = x - x = 0
    \end{align*}
\end{itemize}
\end{proof}

\begin{exercise}
For \(H\) a Hopf algebra with antipode \(S\), show that \(S\left(1_H\right) = 1_H\), \(\varepsilon \circ S = \varepsilon\) and
\[
\begin{cases}
    S(h g) = S(g) S(h) \\[0.5em]
    \Delta (S(h)) = \left((S \tensor S) \circ \tau \circ \Delta\right) (h)
\end{cases} \forall g, h \in H
\]
where \(\tau \colon H \tensor H \to H \tensor H\) is the switch map, \(\tau (x \tensor y) = y \tensor x\), \(\forall x, y \in H\).
\end{exercise}
\begin{proof}
For the first equality, recall that
\[
    m_H (S \tensor \Id) \Delta = \eta \varepsilon
\]
hence
\[
    m_H (S \tensor \Id) \Delta \eta = \eta \varepsilon \eta
\]
Evaluating this expression at \(1 \in k\), we get
\begin{gather*}
    S\left(1_H\right) \cdot 1_H = 1_H \\
    \iff 
    S\left(1_H\right) = 1_H
\end{gather*}

For the second equality, let \(h \in H\) and write the coproduct of \(h\) using Sweedler notation (symbolically, \(\Delta(h) = h_1 \tensor h_2\)). Evaluating the defining relation of the antipode at \(h\), we get
\[
    S\left(h_1\right) \cdot h_2 = \varepsilon(h) \cdot 1_H
\]
Applying \(\varepsilon\) gives us
\begin{align*}    
    \varepsilon \left(S\left(h_1\right) \cdot h_2\right) &= \varepsilon\left(\varepsilon(h) \cdot 1_H\right) \\
    \implies
    \varepsilon \left(S\left(h_1\right) \cdot h_2\right) &= \varepsilon(h) \cdot \varepsilon\left(1_H\right) \tag{\(\varepsilon\) is \(k\)-linear} \\
    \implies
    \varepsilon\left(S(h_1) \cdot h_2\right) &= \varepsilon(h) \tag{\(\varepsilon\) is counit} \\
    \implies
    \varepsilon \left(S\left(h_1\right)\right) \cdot \varepsilon\left(h_2\right) &= \varepsilon(h) \tag{\(\varepsilon\) is a \(k\)-algebra homomorphism} \\
    \implies
    \varepsilon\left(S(h_1) \cdot \varepsilon\left(h_2\right)\right) &= \varepsilon(h) \tag{\(\varepsilon\) is \(k\)-linear} \\
    \implies
    \varepsilon\left(S\left(h_1 \cdot \varepsilon\left(h_2\right)\right)\right) &= \varepsilon(h) \tag{\(S\) is \(k\)-linear} \\
    \implies
    (\varepsilon \circ S)\left(h_1 \cdot \varepsilon\left(h_2\right)\right) &= \varepsilon(h) \\
    \implies
    (\varepsilon \circ S) (h) &= \varepsilon(h)
\end{align*}

Now we will prove the identities related to the antipode and the switch map. Let \(g, h \in H\). Using the defining properties of the antipode, we get
\begin{gather*}
    S\left((h g)_1\right) \cdot (hg)_2 = \varepsilon(hg) \\
    \implies
    S\left((h g)_1\right) \cdot h_2 \cdot g_2 = \varepsilon(h) \cdot \varepsilon(g) \\
    \implies
    S\left((h g)_1\right) \cdot h_2 \cdot g_2 \cdot S\left(h_3\right) \cdot S\left(g_3\right) = \varepsilon\left(h_1\right) \cdot S\left(h_2\right) \cdot \varepsilon\left(g_1\right) \cdot S\left(g_2\right) \\
    \implies
    S\left((h g)_1\right) \cdot h_2 \cdot g_2 \cdot S\left(h_3\right) \cdot S\left(g_3\right) = \varepsilon\left(g_1\right) \cdot S\left(g_2\right) \cdot \varepsilon\left(h_1\right) \cdot S\left(h_2\right) \\
    \implies
    S\left(h_1 g_1\right) \cdot \varepsilon\left(h_2\right) \cdot \varepsilon\left(g_2\right) = S(g) S(h) \\
    \implies
    S\left(h_1 \cdot \varepsilon\left(h_2\right) \cdot g_1 \cdot \varepsilon\left(g_2\right)\right) =  S(g) S(h) \\
    \implies
    S(hg) = S(g) S(h)
\end{gather*}

The identity proven above shows that
\[
    S \circ m_H = m_H \circ \tau \circ (S \tensor S)
\]
By ``reversing all of the arrows'' in the corresponding commutative diagram, we have
\[
    \Delta \circ S = (S \tensor S) \circ \tau \circ \Delta
\]
which can be proven just like before, but dualizing the computations.
\end{proof}
